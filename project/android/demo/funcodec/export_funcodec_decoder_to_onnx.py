#!/usr/bin/env python3
"""
FunCodec è§£ç å™¨å¯¼å‡ºä¸º ONNXï¼Œå¹¶å¢åŠ äº†ä»æ–‡ä»¶è§£ç çš„åŠŸèƒ½ã€‚
- æ¨¡å¼ä¸€ (é»˜è®¤): å¯¼å‡ºONNXæ¨¡å‹å¹¶éªŒè¯ã€‚
    python export_funcodec_decoder_to_onnx.py --model_dir exp/audio_codec-encodec-en-libritts-16k-nq32ds640-pytorch
- æ¨¡å¼äºŒ: ä»æ–‡ä»¶è¯»å–ç¼–ç å¹¶ç”¨PyTorchæ¨¡å‹è§£ç ä¸ºéŸ³é¢‘ã€‚
    python export_funcodec_decoder_to_onnx.py --model_dir exp/audio_codec-encodec-en-libritts-16k-nq32ds640-pytorch --decode_file result_example.txt --output_wav decoded_audio.wav
- æ¨¡å¼ä¸‰ (æ–°å¢): ä½¿ç”¨ONNXæ¨¡å‹ä»æ–‡ä»¶è¯»å–ç¼–ç å¹¶è§£ç ä¸ºéŸ³é¢‘ã€‚
    python export_funcodec_decoder_to_onnx.py --onnx_decode_file result_example.txt --onnx_path funcodec_decoder.onnx --output_wav decoded_onnx_audio.wav
"""

# è§£å†³ einops ä¸ torch.onnx å¯¼å‡ºå†²çªçš„çŒ´å­è¡¥ä¸
import types, sys

fake_dynamo = types.ModuleType("torch._dynamo")
setattr(fake_dynamo, 'allow_in_graph', lambda _a, *kw: None)
setattr(fake_dynamo, 'trace_rules', {})
sys.modules["torch._dynamo"] = fake_dynamo

import argparse
import os
import sys
import yaml
import torch
import torch.nn as nn
import numpy as np
from argparse import Namespace

try:
    import onnx
    import onnxruntime
except ImportError:
    # åœ¨è§£ç æ¨¡å¼ä¸‹ï¼Œè¿™äº›ä¸æ˜¯å¿…éœ€çš„
    onnx, onnxruntime = None, None

try:
    from scipy.io import wavfile
except ImportError:
    print("è¯·å®‰è£… scipy: pip install scipy")
    sys.exit(1)

# ======================= ONNX EXPORT MONKEY PATCH =======================
print(">>> Applying DEFINITIVE ONNX export monkey patch for FunCodec SConv1d...")
import funcodec.modules.normed_modules.conv as conv_module
from torch.nn import functional as F


def _onnx_safe_sconv1d_forward(self, x):
    kernel_size, = self.conv.conv.kernel_size
    stride, = self.conv.conv.stride
    dilation, = self.conv.conv.dilation

    if self.causal:
        padding_total = (kernel_size - 1) * dilation
        x = conv_module.pad1d(x, (padding_total, 0), mode=self.pad_mode)
        return self.conv(x)
    else:
        padding_total_effective = (kernel_size - 1) * dilation - (stride - 1)
        length_tensor = x.new_tensor(x.shape[-1], dtype=torch.float32)
        n_frames = (length_tensor - kernel_size + padding_total_effective) / stride + 1
        ideal_length = (torch.ceil(n_frames) - 1) * stride + (kernel_size - padding_total_effective)
        extra_padding = (ideal_length - length_tensor).to(torch.long)

        padding_left = padding_total_effective // 2
        padding_right = padding_total_effective - padding_left

        padded_x = F.pad(x, (padding_left, 0), mode=self.pad_mode)
        right_pad_size = padding_right + extra_padding

        max_padding_buffer = 2048
        zeros_buffer = torch.zeros(x.shape[0], x.shape[1], max_padding_buffer, device=x.device, dtype=x.dtype)
        dynamic_padding_tensor = zeros_buffer.narrow(-1, 0, right_pad_size)
        padded_x = torch.cat([padded_x, dynamic_padding_tensor], dim=-1)

        return self.conv(padded_x)


conv_module.SConv1d.forward = _onnx_safe_sconv1d_forward
print(">>> Monkey patch for SConv1d applied successfully.")
# ======================================================================

from funcodec.tasks.gan_speech_codec import GANSpeechCodecTask


def parse_args():
    p = argparse.ArgumentParser(description="FunCodec Decoder ONNX Exporter and File Decoder")
    p.add_argument('--model_dir',
                   help='FunCodec é¢„è®­ç»ƒæ¨¡å‹ç›®å½• (åº”åŒ…å« config.yaml å’Œ *.pt/.pth)')

    # ONNXç›¸å…³å‚æ•°
    p.add_argument('--onnx_path', default='funcodec_decoder.onnx',
                   help='è¾“å‡ºçš„ ONNX æ¨¡å‹è·¯å¾„')
    p.add_argument('--opset', type=int, default=14,
                   help='ONNX opset ç‰ˆæœ¬')
    p.add_argument('--codebook_size', type=int, default=1024,
                   help='ç æœ¬å¤§å°,ç”¨äºç”Ÿæˆdummy input')

    # æ–‡ä»¶è§£ç ç›¸å…³å‚æ•°
    p.add_argument('--decode_file', type=str, default=None,
                   help='ä»æŒ‡å®šæ–‡ä»¶è¯»å–ç¼–ç å¹¶ç”¨PyTorchæ¨¡å‹è§£ç ä¸ºéŸ³é¢‘')
    p.add_argument('--onnx_decode_file', type=str, default=None,
                   help='ä»æŒ‡å®šæ–‡ä»¶è¯»å–ç¼–ç å¹¶ç”¨ONNXæ¨¡å‹è§£ç ä¸ºéŸ³é¢‘')
    p.add_argument('--output_wav', type=str, default='decoded_from_file.wav',
                   help='è§£ç åçš„éŸ³é¢‘è¾“å‡ºè·¯å¾„')

    return p.parse_args()


def topdict_to_ns(d):
    return Namespace(**d)


def build_codec(model_dir):
    config_path = os.path.join(model_dir, 'config.yaml')
    with open(config_path, 'r') as f:
        cfg_dict = yaml.safe_load(f)
    cfg = topdict_to_ns(cfg_dict)
    codec = GANSpeechCodecTask.build_model(cfg)

    weight_path = None
    for name in ["model.pth", "valid.loss.ave.pt", "train.loss.ave.pt"]:
        p = os.path.join(model_dir, name)
        if os.path.exists(p):
            weight_path = p
            break

    if weight_path is None:
        pt_files = sorted([p for p in os.listdir(model_dir) if p.endswith((".pt", ".pth"))])
        if not pt_files:
            raise RuntimeError(f"åœ¨ {model_dir} ä¸­æ‰¾ä¸åˆ°ä»»ä½• .pt æˆ– .pth æƒé‡æ–‡ä»¶")
        weight_path = os.path.join(model_dir, pt_files[-1])

    print(f"ä½¿ç”¨æƒé‡æ–‡ä»¶: {weight_path}")
    state_dict = torch.load(weight_path, map_location="cpu")
    codec.load_state_dict(state_dict, strict=True)
    return codec


class DecoderWrapper(nn.Module):
    """
    ä¸€ä¸ªåŒ…è£…å™¨,åŒ…å«FunCodecçš„åé‡åŒ–å™¨å’Œè§£ç å™¨ã€‚
    """

    def __init__(self, codec):
        super().__init__()
        self.quantizer = codec.quantizer
        self.decoder = codec.decoder
        self.hop_length = np.prod(self.decoder.ratios)

    def forward(self, codes):
        codes_transposed = codes.permute(1, 0, 2)
        dequantized_b_t_c = self.quantizer.decode(codes_transposed)
        dequantized_b_c_t = dequantized_b_t_c.permute(0, 2, 1)
        wav = self.decoder(dequantized_b_c_t)
        return wav


def read_codes_from_file(file_path: str, num_quantizers: int = 32) -> torch.Tensor:
    """
    ä»æ–‡æœ¬æ–‡ä»¶ä¸­è¯»å–ç¼–ç ã€‚
    æ–‡ä»¶æ ¼å¼å‡å®šä¸º: æ‰€æœ‰ç¼–ç æ•°å­—ä»¥ç©ºæ ¼æˆ–æ¢è¡Œç¬¦åˆ†éš”ã€‚
    """
    print(f"æ­£åœ¨ä»æ–‡ä»¶ {file_path} è¯»å–ç¼–ç ...")
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"ç¼–ç æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    with open(file_path, 'r') as f:
        content = f.read()

    # å°†æ‰€æœ‰ç©ºç™½ç¬¦ï¼ˆç©ºæ ¼ã€æ¢è¡Œã€åˆ¶è¡¨ç¬¦ï¼‰ä½œä¸ºåˆ†éš”ç¬¦
    str_codes = content.split()
    try:
        int_codes = [int(c) for c in str_codes]
    except ValueError as e:
        print(f"é”™è¯¯: æ–‡ä»¶ {file_path} åŒ…å«éæ•´æ•°å€¼ã€‚")
        raise e

    codes_np = np.array(int_codes, dtype=np.int64)

    # éªŒè¯ç¼–ç æ€»æ•°æ˜¯å¦å¯ä»¥è¢«é‡åŒ–å™¨æ•°é‡æ•´é™¤
    if codes_np.size % num_quantizers != 0:
        raise ValueError(
            f"ç¼–ç æ€»æ•° ({codes_np.size}) æ— æ³•è¢«é‡åŒ–å™¨å±‚æ•° ({num_quantizers}) æ•´é™¤ã€‚"
        )

    # é‡å¡‘ä¸º (B, Nq, T) æ ¼å¼, B=1
    num_frames = codes_np.size // num_quantizers
    codes_reshaped = codes_np.reshape((1, num_quantizers, num_frames))
    print(f"è¯»å–äº† {codes_np.size} ä¸ªç¼–ç , é‡å¡‘ä¸ºå½¢çŠ¶: {codes_reshaped.shape}")

    return torch.from_numpy(codes_reshaped)


def decode_from_file(args, device):
    """
    æ‰§è¡Œä»æ–‡ä»¶è§£ç å¹¶ä¿å­˜ä¸ºWAVçš„æµç¨‹ã€‚
    """
    print("\n" + "=" * 60)
    print("æ¨¡å¼: ä»æ–‡ä»¶è§£ç  (PyTorchæ¨¡å‹)")
    print("=" * 60)

    # 1. æ„å»ºå¹¶åŠ è½½æ¨¡å‹
    codec = build_codec(args.model_dir).to(device).eval()
    wrapper = DecoderWrapper(codec).to(device).eval()

    # 2. ä»æ–‡ä»¶è¯»å–ç¼–ç 
    # en-libritts-16k-nq32ds640 æ¨¡å‹ï¼Œé‡åŒ–å™¨æ•°é‡ä¸º32
    num_quantizers = 32
    try:
        codes_tensor = read_codes_from_file(args.decode_file, num_quantizers)
    except (ValueError, FileNotFoundError) as e:
        print(f"é”™è¯¯: {e}")
        sys.exit(1)

    # 3. ä½¿ç”¨PyTorchæ¨¡å‹è¿›è¡Œè§£ç 
    print("æ­£åœ¨ä½¿ç”¨PyTorchæ¨¡å‹è§£ç ...")
    with torch.no_grad():
        output_wav_tensor = wrapper(codes_tensor.to(device))

    # 4. ä¿å­˜ä¸ºWAVæ–‡ä»¶
    output_wav_np = output_wav_tensor.cpu().numpy().squeeze()
    sample_rate = 16000  # FunCodec libritts æ¨¡å‹çš„æ ‡å‡†é‡‡æ ·ç‡

    try:
        wavfile.write(args.output_wav, sample_rate, output_wav_np)
        print(f"\nğŸ‰ PyTorchæ¨¡å‹è§£ç æˆåŠŸ! éŸ³é¢‘å·²ä¿å­˜åˆ°: {args.output_wav}")
    except Exception as e:
        print(f"\nâŒ ä¿å­˜WAVæ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)


def decode_from_file_onnx(args, device):
    """
    ä½¿ç”¨ONNXæ¨¡å‹æ‰§è¡Œä»æ–‡ä»¶è§£ç å¹¶ä¿å­˜ä¸ºWAVçš„æµç¨‹ã€‚
    """
    print("\n" + "=" * 60)
    print("æ¨¡å¼: ä»æ–‡ä»¶è§£ç  (ONNXæ¨¡å‹)")
    print("=" * 60)

    # æ£€æŸ¥ONNXç›¸å…³ä¾èµ–
    if onnx is None or onnxruntime is None:
        print("é”™è¯¯: ONNXè§£ç æ¨¡å¼éœ€è¦å®‰è£… onnx å’Œ onnxruntimeã€‚")
        print("è¯·è¿è¡Œ: pip install onnx onnxruntime")
        sys.exit(1)

    # 1. æ£€æŸ¥ONNXæ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.onnx_path):
        print(f"é”™è¯¯: ONNXæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.onnx_path}")
        print("è¯·å…ˆå¯¼å‡ºONNXæ¨¡å‹æˆ–æŒ‡å®šæ­£ç¡®çš„ONNXæ¨¡å‹è·¯å¾„ã€‚")
        sys.exit(1)

    # 2. åŠ è½½ONNXæ¨¡å‹
    print(f"æ­£åœ¨åŠ è½½ONNXæ¨¡å‹: {args.onnx_path}")
    try:
        ort_sess = onnxruntime.InferenceSession(args.onnx_path, providers=['CPUExecutionProvider'])
        print("âœ… ONNXæ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ONNXæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        sys.exit(1)

    # 3. ä»æ–‡ä»¶è¯»å–ç¼–ç 
    num_quantizers = 32
    try:
        codes_tensor = read_codes_from_file(args.onnx_decode_file, num_quantizers)
    except (ValueError, FileNotFoundError) as e:
        print(f"é”™è¯¯: {e}")
        sys.exit(1)

    # 4. ä½¿ç”¨ONNXæ¨¡å‹è¿›è¡Œè§£ç 
    print("æ­£åœ¨ä½¿ç”¨ONNXæ¨¡å‹è§£ç ...")
    try:
        codes_numpy = codes_tensor.numpy()
        onnx_output = ort_sess.run(None, {'codes': codes_numpy})[0]
        print(f"ONNXæ¨¡å‹è¾“å‡ºå½¢çŠ¶: {onnx_output.shape}")
    except Exception as e:
        print(f"âŒ ONNXæ¨¡å‹æ¨ç†å¤±è´¥: {e}")
        sys.exit(1)

    # 5. ä¿å­˜ä¸ºWAVæ–‡ä»¶
    output_wav_np = onnx_output.squeeze()
    sample_rate = 16000  # FunCodec libritts æ¨¡å‹çš„æ ‡å‡†é‡‡æ ·ç‡

    try:
        wavfile.write(args.output_wav, sample_rate, output_wav_np)
        print(f"\nğŸ‰ ONNXæ¨¡å‹è§£ç æˆåŠŸ! éŸ³é¢‘å·²ä¿å­˜åˆ°: {args.output_wav}")
    except Exception as e:
        print(f"\nâŒ ä¿å­˜WAVæ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)

    # 6. æ˜¾ç¤ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
    print(f"è§£ç ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  - è¾“å…¥ç¼–ç å¸§æ•°: {codes_tensor.shape[2]}")
    print(f"  - è¾“å‡ºéŸ³é¢‘é‡‡æ ·ç‚¹æ•°: {len(output_wav_np)}")
    print(f"  - éŸ³é¢‘æ—¶é•¿: {len(output_wav_np) / sample_rate:.2f} ç§’")


def main():
    args = parse_args()
    device = 'cpu'

    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°é€‰æ‹©æ‰§è¡Œæ¨¡å¼
    if args.onnx_decode_file:
        # æ¨¡å¼ä¸‰: ä½¿ç”¨ONNXæ¨¡å‹ä»æ–‡ä»¶è§£ç 
        decode_from_file_onnx(args, device)
        return True
    elif args.decode_file:
        # æ¨¡å¼äºŒ: ä½¿ç”¨PyTorchæ¨¡å‹ä»æ–‡ä»¶è§£ç 
        if args.model_dir is None:
            print("é”™è¯¯: ä½¿ç”¨PyTorchæ¨¡å‹è§£ç æ—¶éœ€è¦æŒ‡å®š --model_dir å‚æ•°")
            sys.exit(1)
        decode_from_file(args, device)
        return True

    # æ¨¡å¼ä¸€: å¯¼å‡ºONNXæ¨¡å‹å¹¶éªŒè¯
    if args.model_dir is None:
        print("é”™è¯¯: å¯¼å‡ºONNXæ¨¡å‹æ—¶éœ€è¦æŒ‡å®š --model_dir å‚æ•°")
        sys.exit(1)

    if onnx is None or onnxruntime is None:
        print("é”™è¯¯: ONNXå¯¼å‡ºæ¨¡å¼éœ€è¦å®‰è£… onnx å’Œ onnxruntimeã€‚")
        print("è¯·è¿è¡Œ: pip install onnx onnxruntime")
        return False

    print("\n" + "=" * 60)
    print("æ¨¡å¼: å¯¼å‡ºONNXæ¨¡å‹")
    print("=" * 60)

    # 1. æ„å»ºå¹¶åŠ è½½æ¨¡å‹
    codec = build_codec(args.model_dir).to(device).eval()
    wrapper = DecoderWrapper(codec).to(device).eval()

    # 2. å‡†å¤‡ dummy input
    n_quantizers = 32
    dummy_frames = 50
    dummy_input = torch.randint(
        0, args.codebook_size,
        (1, n_quantizers, dummy_frames),
        dtype=torch.long, device=device
    )
    print(f"ä½¿ç”¨ dummy input, å½¢çŠ¶: {list(dummy_input.shape)}")

    # 3. å¯¼å‡º ONNX æ¨¡å‹
    print(f'\nå¼€å§‹å¯¼å‡º ONNX åˆ° {args.onnx_path} ...')
    torch.onnx.export(
        wrapper, dummy_input, args.onnx_path,
        opset_version=args.opset,
        input_names=['codes'], output_names=['waveform'],
        dynamic_axes={'codes': {2: 'n_frames'}, 'waveform': {2: 'n_samples'}},
        do_constant_folding=True, verbose=False
    )
    print(f'ONNX å¯¼å‡ºå®Œæˆ!')

    # 4. éªŒè¯ ONNX æ¨¡å‹
    print("\n" + "=" * 60)
    print("éªŒè¯ ONNX æ¨¡å‹åŠ¨æ€å½¢çŠ¶")
    print("=" * 60)

    onnx_model = onnx.load(args.onnx_path)
    onnx.checker.check_model(onnx_model)
    print("âœ… ONNXæ¨¡å‹ç»“æ„æ£€æŸ¥é€šè¿‡")

    ort_sess = onnxruntime.InferenceSession(args.onnx_path, providers=['CPUExecutionProvider'])

    test_frames = [50, 125]
    all_passed = True
    onnx_shapes = []
    sample_rate = 16000

    for n_frames in test_frames:
        test_codes = torch.randint(0, args.codebook_size, (1, n_quantizers, n_frames), dtype=torch.long)

        with torch.no_grad():
            pytorch_output = wrapper(test_codes.to(device)).cpu().numpy()

        try:
            onnx_output = ort_sess.run(None, {'codes': test_codes.numpy()})[0]
        except Exception as e:
            print(f"âŒ ONNXæ¨ç†å¤±è´¥ (å¸§æ•°: {n_frames}): {e}")
            all_passed = False
            continue

        print(f"å¸§æ•°: {n_frames:4d} -> PyTorch: {pytorch_output.shape}, ONNX: {onnx_output.shape}")

        pytorch_wav_path = f"pytorch_output_{n_frames}frames.wav"
        wavfile.write(pytorch_wav_path, sample_rate, pytorch_output.squeeze())
        print(f"  ğŸµ å·²ä¿å­˜PyTorchè¾“å‡ºåˆ°: {pytorch_wav_path}")

        onnx_wav_path = f"onnx_output_{n_frames}frames.wav"
        wavfile.write(onnx_wav_path, sample_rate, onnx_output.squeeze())
        print(f"  ğŸµ å·²ä¿å­˜ONNXè¾“å‡ºåˆ°: {onnx_wav_path}")

        onnx_shapes.append(onnx_output.shape)

        if pytorch_output.shape != onnx_output.shape:
            print(f"  âŒ å½¢çŠ¶ä¸åŒ¹é…!")
            all_passed = False
        else:
            print("  âœ… å½¢çŠ¶åŒ¹é…")

    if len(set(onnx_shapes)) == 1 and len(test_frames) > 1:
        print(f"\nâŒ ONNXè¾“å‡ºå½¢çŠ¶å›ºåŒ–: {onnx_shapes[0]}")
        all_passed = False
    else:
        print(f"\nâœ… ONNXè¾“å‡ºå½¢çŠ¶åŠ¨æ€")

    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print(f"\nğŸ’¡ æç¤º: ç°åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æµ‹è¯•ONNXæ¨¡å‹çš„æ–‡ä»¶è§£ç åŠŸèƒ½:")
        print(
            f"python {sys.argv[0]} --onnx_decode_file your_codes.txt --onnx_path {args.onnx_path} --output_wav onnx_decoded.wav")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥")

    return all_passed


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)